// Targeted by JavaCPP version 1.5.10: DO NOT EDIT THIS FILE

package us.ihmc.zed;

import org.bytedeco.cuda.cudart.CUctx_st;
import org.bytedeco.cuda.cudart.CUstream_st;
import java.nio.*;
import org.bytedeco.javacpp.*;
import org.bytedeco.javacpp.annotation.*;

import static us.ihmc.zed.global.zed.*;


/**
\brief Structure containing a set of parameters for the object detection module.
<p>
The default constructor sets all parameters to their default settings.
\note Parameters can be user adjusted.
*/
@Properties(inherit = us.ihmc.zed.ZEDJavaAPIConfig.class)
public class SL_ObjectDetectionParameters extends Pointer {
    static { Loader.load(); }
    /** Default native constructor. */
    public SL_ObjectDetectionParameters() { super((Pointer)null); allocate(); }
    /** Native array allocator. Access with {@link Pointer#position(long)}. */
    public SL_ObjectDetectionParameters(long size) { super((Pointer)null); allocateArray(size); }
    /** Pointer cast constructor. Invokes {@link Pointer#Pointer(Pointer)}. */
    public SL_ObjectDetectionParameters(Pointer p) { super(p); }
    private native void allocate();
    private native void allocateArray(long size);
    @Override public SL_ObjectDetectionParameters position(long position) {
        return (SL_ObjectDetectionParameters)super.position(position);
    }
    @Override public SL_ObjectDetectionParameters getPointer(long i) {
        return new SL_ObjectDetectionParameters((Pointer)this).offsetAddress(i);
    }

	/**
	\brief Id of the module instance.
	<p>
	This is used to identify which object detection module instance is used.
	 */
	public native @Cast("unsigned int") int instance_module_id(); public native SL_ObjectDetectionParameters instance_module_id(int setter);

	/**
	\brief Whether the object detection system includes object tracking capabilities across a sequence of images.
	<p>
	Default: true
	 */
	public native @Cast("bool") boolean enable_tracking(); public native SL_ObjectDetectionParameters enable_tracking(boolean setter);
	/**
	\brief Whether the object masks will be computed.
	<p>
	Default: false
	 */
	public native @Cast("bool") boolean enable_segmentation(); public native SL_ObjectDetectionParameters enable_segmentation(boolean setter);
	/**
	\brief \ref SL_OBJECT_DETECTION_MODEL to use.
	
	Default: \ref SL_OBJECT_DETECTION_MODEL_MULTI_CLASS_BOX_FAST
	 */
	public native @Cast("SL_OBJECT_DETECTION_MODEL") int detection_model(); public native SL_ObjectDetectionParameters detection_model(int setter);

	/**
	\brief In a multi camera setup, specify which group this model belongs to.
	<p>
	In a multi camera setup, multiple cameras can be used to detect objects and multiple detector having similar output layout can see the same object.
	Therefore, Fusion will fuse together the outputs received by multiple detectors only if they are part of the same \ref fused_objects_group_name.
	<p>
	\note This parameter is not used when not using a multi-camera setup and must be set in a multi camera setup.
	*/
	public native @Cast("char*") BytePointer fused_objects_group_name(); public native SL_ObjectDetectionParameters fused_objects_group_name(BytePointer setter);

	/**
	\brief Path to the YOLO-like onnx file for custom object detection ran in the ZED SDK.
	<p>
	When {@code detection_model} is \ref OBJECT_DETECTION_MODEL::CUSTOM_YOLOLIKE_BOX_OBJECTS, a onnx model must be passed so that the ZED SDK can optimize it for your GPU and run inference on it.
	<p>
	The resulting optimized model will be saved for re-use in the future.
	<p>
	\attention - The model must be a YOLO-like model.
	\attention - The caching uses the {@code custom_onnx_file} string along with your GPU specs to decide whether to use the cached optmized model or to optimize the passed onnx model.
		If you want to use a different model (i.e. an onnx with different weights), you must use a different {@code custom_onnx_file} string or delete the cached optimized model in
		<ZED Installation path>/resources.
	<p>
	\note This parameter is useless when detection_model is not \ref OBJECT_DETECTION_MODEL::CUSTOM_YOLOLIKE_BOX_OBJECTS.
	*/
	public native @Cast("char*") BytePointer custom_onnx_file(); public native SL_ObjectDetectionParameters custom_onnx_file(BytePointer setter);

	/**
	\brief Resolution to the YOLO-like onnx file for custom object detection ran in the ZED SDK. This resolution defines the input tensor size for dynamic shape ONNX model only. The batch and channel dimensions are automatically handled, it assumes it's color images like default YOLO models.
	<p>
	\note This parameter is only used when detection_model is \ref OBJECT_DETECTION_MODEL::CUSTOM_YOLOLIKE_BOX_OBJECTS and the provided ONNX file is using dynamic shapes.
	\attention - Multiple model only support squared images
		
	\default Squared images 512x512 (input tensor will be 1x3x512x512)
		*/
	public native @ByRef SL_Resolution custom_onnx_dynamic_input_shape(); public native SL_ObjectDetectionParameters custom_onnx_dynamic_input_shape(SL_Resolution setter);

	/**
	\brief Upper depth range for detections.
	
	Default: -1.f (value set in SL_InitParameters.depth_maximum_distance)
	\note The value cannot be greater than SL_InitParameters.depth_maximum_distance and its unit is defined in SL_InitParameters.coordinate_unit.
	 */
	public native float max_range(); public native SL_ObjectDetectionParameters max_range(float setter);
	/**
	 \brief Batching system parameters.
	<p>
	Batching system (introduced in 3.5) performs short-term re-identification with deep-learning and trajectories filtering.
	\n SL_BatchParameters.enable must to be true to use this feature (by default disabled).
	 */
	public native @ByRef SL_BatchParameters batch_parameters(); public native SL_ObjectDetectionParameters batch_parameters(SL_BatchParameters setter);
	/**
	\brief Filtering mode that should be applied to raw detections.
	<p>
	Default: \ref SL_OBJECT_FILTERING_MODE_NMS_3D (same behavior as previous ZED SDK version)
	\note This parameter is only used in detection model [SL_OBJECT_DETECTION_MODEL_MULTI_CLASS_BOX_XXX](\ref SL_OBJECT_DETECTION_MODEL)
	and \ref SL_OBJECT_DETECTION_MODEL_CUSTOM_BOX_OBJECTS.
	\note For custom object, it is recommended to use \ref SL_OBJECT_FILTERING_MODE_NMS_3D_PER_CLASS or \ref SL_OBJECT_FILTERING_MODE_NONE.
	\note In this case, you might need to add your own NMS filter before ingesting the boxes into the object detection module.
	*/
	public native @Cast("SL_OBJECT_FILTERING_MODE") int filtering_mode(); public native SL_ObjectDetectionParameters filtering_mode(int setter);

	/**
	\brief Prediction duration of the ZED SDK when an object is not detected anymore before switching its state to \ref SL_OBJECT_TRACKING_STATE_SEARCHING.
	
	It prevents the jittering of the object state when there is a short misdetection.
    \n The user can define their own prediction time duration.
	\n Default: 0.2f
    \note During this time, the object will have \ref SL_OBJECT_TRACKING_STATE_OK state even if it is not detected.
    \note The duration is expressed in seconds.
    \warning \ref prediction_timeout_s will be clamped to 1 second as the prediction is getting worse with time.
    \warning Setting this parameter to 0 disables the ZED SDK predictions.
	*/
	public native float prediction_timeout_s(); public native SL_ObjectDetectionParameters prediction_timeout_s(float setter);
	/**
	\brief Whether to allow inference to run at a lower precision to improve runtime and memory usage.
	<p>
	It might increase the initial optimization time and could include downloading calibration data or calibration cache and slightly reduce the accuracy.
	\note The fp16 is automatically enabled if the GPU is compatible and provides a speed up of almost x2 and reduce memory usage by almost half, no precision loss.
	\note This setting allow int8 precision which can speed up by another x2 factor (compared to fp16, or x4 compared to fp32) and half the fp16 memory usage, however some accuracy could be lost.
	\note The accuracy loss should not exceed 1-2% on the compatible models.
	\note The current compatible models are all [SL_AI_MODELS_HUMAN_BODY_XXXX](\ref SL_AI_MODELS).
	 */
	public native @Cast("bool") boolean allow_reduced_precision_inference(); public native SL_ObjectDetectionParameters allow_reduced_precision_inference(boolean setter);
}
